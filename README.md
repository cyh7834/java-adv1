# [김영한님] 김영한의 실전 자바 - 고급 1편, 멀티스레드와 동시성
스레드의 기본기와 생명주기, 스레드를 다루는 여러 기술을 통해 현재 주로 사용되고 있는 Executor 프레임워크가 어떤 기반으로 구현되어 있는지,<br>
실무에서 어떤 방식으로 유연하게 활용할 수 있는지에 대한 방법을 배우게 됐다.

## 배운점
- 사용자 스레드, 데몬 스레드<br>
사용자 스레드는 프로그램의 주요 작업을 수행하고 모든 사용자 스레드가 종료되어야 JVM도 종료가 된다.<br>
데몬 스레드는 백그라운드에서 보조적인 작업을 수행하고, 작업 완료 여부에 상관없이 모든 사용자 스레드가 종료되면 데몬 스레드도 자동으로 종료된다.<br>

- 스레드 생명주기<br>
New -> 처음 스레드가 생성되었을 때의 상태<br>
Runnable -> 스레드가 실행되기 위해 대기 큐에 진입하거나, 실제로 실행되고 있을 때의 상태<br>
Blocked -> 임계 영역에 진입하기 위한 lock을 얻고자 기다리는 상태<br>
Waiting -> 스레드가 다른 스레드의 특정 작업이 완료되기를 무기한 기다리는 상태<br>
Timed Waiting -> 스레드가 특정 시간 동안 다른 스레드의 작업이 완료되기를 기다리는 상태<br>
Terminated -> 스레드의 실행이 완료되거나 예외가 발생하여 종료된 경우의 상태<br>

- 메모리 가시성<br>
메인 메모리는 CPU의 입장에선 거리가 멀고, 속도도 상대적으로 느리다. CPU 연산은 매우 빠르기 때문에 CPU 연산의 빠른 성능을 따라가려면,<br>
CPI 가까이에 매우 빠른 메모리가 필요하고, 그것이 바로 캐시 메모리이다.<br>
현대의 CPU 대부분은 코어 단위로 캐시 메모리를 보유하고 있다.<br>
스레드 클래스의 클래스 변수 값을 메인 스레드에서 변경하려해도 각 스레드들은 캐시 메모리에 클래스 변수 값을 일정 시간동안 캐싱하고 있기 때문에<br>
즉각 반영이 안되어 기대했던 것과 다르게 다르게 동작할 수 있다.<br>
이처럼 멀티스레드 환경에서 한 스레드가 변경한 값이 다른 스레드에서 언제 보이는지에 대한 문제를 '메모리 가시성'이라고 한다.<br>
캐시 메모리를 사용하면 성능이 더 빠를 순 있지만 정확한 데이터를 확인할 수 없는 상황이 발생한다. 해결 방법은 성능을 약간 포기하는 대신에,<br>
값을 읽을 때, 쓸 때 모두 메인 메모리에 직접 접근하면되고 자바에서는 'volatile'이라는 키워드로 이런 기능을 제공한다.<br>

- 동기화<br>
동기화 문제의 예시로 유명한 계좌 출금 예시로 살펴보았다. 여러 스레드가 하나의 계좌 정보를 동시에 참조하여 출금할 때 잔액이 마이너스가 되는 상황에 대한 문제이다.<br>
잔액은 여러 스레드가 사용하는 '공유 자원'이기 출금 기능을 한번에 하나의 스레드만 실행할 수 있는 '임계 영역'으로 정해야한다.<br>
메소드에 synchronized 약어를 붙혀 임계 영억으로 설정하여 하나의 스레드만 해당 메소드를 수행할 수 있게 만든다.<br>
모든 객체는 내부에 자신만의 lock을 가지고 있다. 해당 lock을 스레드가 점유하여 사용하고 있을 때, 다른 스레드는 해당 객체의 메소드를 사용하기 위해선<br>
lock을 얻기 위해 대기해야 한다. (Blocked 상태)<br>
메소드 전체에 synchronized 키워드를 사용하는 것은 성능 낭비가 발생할 수 있기 때문에 메소드 내에 특정 임계 영역을 세분화하는 것이 중요하다.<br>
이러한 lock 획득 방식은 lock을 얻기 위한 무한 대기, 스레드 간의 공정성 문제가 발생할 수 있다.<br>

- 고급 동기화<br>
Lock 인터페이스와 ReentrantLock 구현체를 사용하여 위의 단점을 해결할 수 있다.<br>
synchronized 블럭보다 더 유연하고, 락을 얻지 못하는 상황에선 바로 빠져나오거나, 락을 일정 시간 만큼만 얻기 위해 대기하는 등의 기능을 제공한다.<br>

- 생산자, 소비자 문제<br>
데이터 처리를 요청하는 생산자와, 데이터 처리를 담당하는 소비자, 그 사이의 버퍼에서 발생할 수 있는 문제들이다. 둘 중 하나가 너무 빠르거나 느려서<br>
버퍼가 꽉 차거나 비게되어 효율이 떨어지는 문제가 발생한다.<br>
버퍼가 꽉 차거나 비게되었을 때 해당 스레드를 종료시키지 않고 기다리게하여 문제를 해결할 수 있을 것이라 생각이 든다. 하지만 단순 sleep을 사용하여 대기하는 것은<br>
스레드가 영원히 종료되지 않아 대기하거나, 데이터 처리를 완전히 하지 못하는 또 다른 문제가 발생한다.<br>
단순히 대기하는 것이 아니라 lock을 다른 스레드에게 양보하게되면 문제를 해결할 수 있다.<br>
wait 메소드를 사용하여 대기가 아닌 lock을 반납하고, 수행을 완료하면 notify 메소드를 통해 다른 스레드를 깨운다.<br>
이 해결방안은 임의의 스레드를 깨우기 때문에 무조건 상황에 맞는 스레드가 깨어난다는 보장을 할 수 없는 비효율이 발생한다.<br>
생산자는 자신의 작업을 수행하고 나서 소비자를 깨워야하고, 소비자는 반대로 생산자를 깨워야 효율적이기 때문이다.<br>
Lock 인터페이스에서 제공하는 Condition 객체를 사용하여 이 비효율을 해결할 수 있고 이러한 기능을 이미 BlockingQueue에서 제공한다.<br>

- CAS 동기화와 원자적 연산<br>
멀티스레드 상황에서 다른 스레드의 간섭 없이 안전하게 처리되는 연산(ex int i = 1).<br>
i = i + 1과 같은 연산은 먼저 i의 값을 읽고 1을 더한 후에 i에 대입하는 연산이기 때문에 여러 스레드가 동시에 수행하게 되면 문제가 발생할 수 있다.<br>
락을 걸어도 되지만, AtomicInteger, AtomicLong 등과 같은 클래스를 사용하여 원자적 연산을 수행할 수 있다.<br>

- 스레드 풀과 Executor 프레임워크<br>
스레드를 직접 생성하여 사용하는 문제는 생성 시간, 관리, 인터페이스의 불편함 등의 많은 문제점이 있다. 이러한 문제를 해결하기 위해<br>
Executor 프레임워크를 통해 스레드 관리 풀을 사용해야한다.<br>
Runnable의 run 메소드는 값을 전달할 수 없기 때문에 메인 메소드는 join을 통해 대기하고 해당 값을 읽어서 사용해야하는 불편함이 있었다.<br>
Callable 인터페이스를 사용하여 값을 직접 반환할 수 있고, Future를 통해 반환 받을 수 있다.<br>
Future는 Callable을 submit하면 작업이 완료되지 않아도 바로 반환되고, 요청 스레드는 전달 값이 필요할 때 Future의 get 메소드를 호출하여<br>
값을 받을 수 있다. join과는 다르게 필요에 따라 get을 호출하여 무작정 기다리지 않아도 되고, 여러 개의 Feature를 사용하면<br>
여러 작업을 한번에 기다릴 수 있기 때문에 더욱 효율적이다 (submit을 한번에 만들고 그 후에 get을 한번에 호출해야 함. invokeAll 메소드 활용 가능.).<br>
cancel 메소드를 통해 작업을 상황에 맞게 취소할 수도 있고, 예외를 전달받을 수도 있다.<br>

- 실무에서의 Executor 프레임워크 활용<br>
서버에 문제가 발생하여 재시작이 필요할 때, 새로운 요청은 막고, 이미 진행 중인 요청은 처리를 한 후에 서버를 재시작하는 것이 가장 좋을 것이다.<br>
shutdown 메소드를 통해 새로운 작업을 받지 않고, 기존의 작업은 모두 완료 후에 종료할 수 있고, shutdownNow 메소드를 통해<br>
작업을 강제로 모두 중단하고 대기 중인 작업도 반환할 수 있다.<br>
물론 이미 들어온 작업을 모두 처리하고 서버를 재시작하는 것이 가장 좋은 방법이지만, 큐에 대기중인 작업이 너무 많거나, 특정 버그로 인해<br>
작업이 끝나지 않는 상황이 발생했을 수도 있다.<br>
그렇기 때문에 먼저 shutdown 메소드를 통해 진행 중이거나 큐에 있는 작업을 처리 한 후에 종료를 시도하고, awaitTermination 메소드를 통해<br>
특정 시간동안 이후에도 정상 종료가 이뤄지지 않는 상황을 확인 후 shutdownNow를 통해 스레드 풀을 강제로 종료하는 방식이 좋다.<br>
또한 서비스 환경에 맞는 풀 전략을 사용하는 것이 좋다.<br>
고정 풀 전략은 ThreadPoolExecutor에 고정된 스레드만 생성하고 초과 스레드는 생성하지 않는 방식이다. 큐 사이즈에도 제한이 없기 때문에<br>
CPU, 메모리 리소스가 어느정도 예측 가능한 안정적인 방식이지만, 사용자가 많아졌을 때 스레드의 크기는 고정되어있기 때문에 큐에 무한대로 요청이 쌓이게 되고<br>
서버 자원을 제대로 활용하지 못하면서 응답시간만 늘어나는 상황이 발생한다.<br>
캐시 풀 전략은 이와 반대로 초과 스레드 수의 제한 없이 모든 요청에 대해 스레드를 생성하여 처리하는 방식이다.<br>
SynchronousQueue를 사용하기 때문에 큐에 내부 저장공간 없이 생상잔의 작업을 바로 소비자 스레드에게 직접 전달한다.<br>
그렇기 때문에 요청이 많을 때는 서버 자원을 최대로 사용할 수 있고, 요청이 없을 땐 스레드 수를 감소시켜 유연하게 사용할 수 있다.<br>
하지만 처리량 대비 요청이 많아지게 되면 시스템이 멈추는 장애가 발생할 수 있다.<br>
사용자 정의 풀 전략은 스레드 크기 고정, 최대 스레드 고정, 특정 크기의 대기 큐를 사용하는 방식이다.<br>
기본 스레드가 다 사용되면 대기 큐에 요청이 쌓이고, 대기 큐도 가득차게되면 긴급 스레드(최대 스레드 크기)를 생성하여 작업을 처리할 수 있다.<br>
큐 사이즈를 무한대가 아닌 일정 크기로 생성해야 추가 스레드가 생성된다.<br>
큐도 가득차고 추가 스레드도 생성할 수 없는 상황일 때는 작업을 거절해야 하는데, 기본 예외를 발생시키거나, 조용히 버리거나,<br>
작업을 요청한 스레드가 직접 작업을 수행하게 하거나, 커스텀 예외를 발생 시킬 수 있는 예외 정책들도 존재한다.
